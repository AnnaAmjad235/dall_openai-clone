<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dall e open AI</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <img width="234px" height="123px" src="logo remover - Copy.png" alt="">
        <div class="headerleft">

            <div class="div">Research</div>
            <div class="div">API</div>
            <div class="div">ChatGPT</div>
            <div class="div">Safety</div>
            <div class="div">Company</div>
        </div>

            <div class="headerright" >
                <h1 class="headingsearch">Search</h1>
                <h3><a class="link"  href="https://www.upwork.com/ab/account-security/login">Login&#8599;</a></h3>
                <button class="btn2"><a  class="anchor" href="https://chat.openai.com/auth/login">Try ChatGPT &#8599;</a></button>
            </div>
        </header>
        
            <div class="centerheading">
                <h1 class="headingdall">DALL·E 2</h1>     
                <p class="pargraph"> DALL·E 2
                    DALL·E 2 is an AI system that can create realistic images <br> and art from a description <br> 
                    in natural language. <br>
                </p> 
               <button class="btn1" >Try DALL.E &#8599;</button>   
               <a class="link2" href="">Follow on instagram&#8599;</a> 
           </div>

           <iframe class="iframe" src="https://www.youtube.com/embed/qTgPSKKjfVg?si=DaKzxw3FA_IDQ1y9" 
           title="YouTube video player"
           frameborder="0" 
           allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
           allowfullscreen></iframe>
           <h1><a class="w" href="https://www.youtube.com/watch?v=qTgPSKKjfVg">&#8227; DALL.E2 explained</a></h1>


       <hr>

<h1 class="latest">Latest Updates</h1>
<a class="link4" href="https://openai.com/blog">view all updates</a>
<div class="div3" >
    <figure>
        <img class="img"  src="pic1.avif" alt="">
        <figcaption><a class="a" href="https://openai.com/blog/dall-e-api-now-available-in-public-beta">DALL·E API now available in public beta <br>
            Nov 3, 2022 <br>
            </a></figcaption>
    </figure>
    <figure>
        <img class="img" src="pic2.avif" alt="">
        <figcaption style="color: white;">DALL·E 2: Extending creativity <br>
            Jul 14, 2022 <br>
            </figcaption>
    </figure>
    <figure>
        <img class="img" src="pic 3.avif" alt="">
        <figcaption style="color: white;">DALL·E now available without waitlist <br>
            Sep 28, 2022</figcaption>
    </figure>
    <figure>
        <img class="img" src="pic 4.avif" alt="">
        <figcaption style="color: white;"> DALL·E: Introducing outpainting <br>
            Aug 31, 2022</figcaption>
    </figure>
</div>
<hr>
<p style=" color: white; font-size: 68px; text-align: justify;">
DALL·E 2 can create original, 
realistic images and art from a text description. 
It can combine concepts, attributes, and styles.</p>

<ul class="ul">
<li><u>imageGeneration</u></li>
<li class="li">Out Painting</li>
<li class="li">Inpainting</li>
<li class="li">Variations</li>
</ul>
<hr>

<h3 style="color: white; text-align: justify; font-size: 34px;">
    DALL·E 2 can create original,
    realistic images and art from a text
     description.  It can combine concepts,attributes, and styles.</h3>
   <a class="link67" href="https://auth0.openai.com/u/login/identifier?state=hKFo2SBwUFA2Q2d5bElFUlE0MEhmbHBYd1c3SGZ5Mmg4Q002b6Fur3VuaXZlcnNhbC1sb2dpbqN0aWTZIDFOczY4RG9RV3ctX09xOW1FSHpBQy0waG5KaGdmZmVUo2NpZNkgRE1nOTFmNVBDSFF0Yzd1MDE4V0tpTDB6b3BLZGlIbGU">Try DALL.E&#8227;</a>

   <div class="div4" >
        <h4 style="color: grey; line-height: 56px; margin-left:12px; font-size: 20px; font-family: Verdana, Geneva, Tahoma, sans-serif; "  >input <br>
            An astronaut riding a horse in photorealistic style. </h4>
            <hr>
            <h4 style="color: white; margin-left: 12px; font-size: 20px; font-family: Verdana, Geneva, Tahoma, sans-serif;  ">Output</h4>
            <img class="marginlet" width="489px" height="543px" src="Anastronautridingahorseinaphotorealisticstyle6.jpg" alt="">
   </div>
   <hr>
   <p style="color: white; text-align: justify; font-size:56px;">
    In January 2021, OpenAI introduced DALL·E.
     One  year later, our newest system, DALL·E 2, generates 
      more realistic and accurate images with 4x greater resolution.</p>

    <div class="divwe">
        <figure>
            <img class="dall" src="dall-e-1.avif" alt="">
        
         </figure>
         <figure>
           <img class="dall" src="dall-e-2.jpg" alt="">
 
         </figure>
    </div>
  <hr>
  <h1 style="color: white; ">
    DALL·E 2 is preferred over <br> DALL·E 1 when evaluators <br> compared each model.

    <div class="bcv" >
          <figure>
            1071.7%
            <figcaption>preferred for caption matching</figcaption>
          </figure>

          <figure>
            88.8%
              <figcaption>preferred for photorealism</figcaption>
          </figure>
    </div>
</h1>
  <hr>
  <h1 style="color: white;">Related Search</h1>
<div class="divpic2">
 
   <figure>
    <img class="divpic2" src="squirelpic.avif" alt="">
    <figcaption class="divpic2" >Hierarchical text-conditional image generation with CLIP latents
        Apr 13, 2022</figcaption>
   </figure>
   <figure>
    <img class="divpic2" src="dall-e round.avif" alt="">
    <figcaption class="divpic2">DALL·E: Creating images from text
        Jan 5, 2021</figcaption>
   </figure>
   <figure>
    <img class="divpic2" src="dall-e-2-pre-training-mitigations.avif" alt="">
    <figcaption class="divpic2" >DALL·E 2 pre-training mitigations
        Jun 28, 2022</figcaption>
   </figure>
  
    <figure>
        <img class="divpic2" src="clip.avif" alt="">
        <figcaption class="divpic2">CLIP: Connecting text and images
            Jan 5, 2021</figcaption>
    </figure>
</div>
<hr>
<h1 style="color: white;">A focus on Safety
    </h1>
    <p class="e">
            DALL·E 2 began as a research project and is now available in beta. Safety mitigations we have developed and continue to improve upon include:
            Preventing harmful generations
            We’ve limited the ability for DAL.
            ']
    </p>
<h1 style="color: white;">
Preventing harmful generations
We’ve limited the ability for DALL·E 2 to generate violent, hate, or adult images. By removing the most explicit content from the training data, we minimized DALL·E 2’s exposure to these concepts. We also used advanced techniques to prevent photorealistic generations of real individuals’ faces, including those of public figures.

</h1>
<hr>
<h1>
    Curbing misuse
</h1>
<p style="color: white; font-size: xx-large;">Learning from real-world use is an important part of developing and deploying AI responsibly. We began by previewing DALL·E 2 to a limited number of trusted users. As we learned more about the technology’s capabilities and limitations, and gained confidence in our safety systems, we slowly added more users and made DALL·E available in beta in July 2022.
  
</p>
<hr>
<p>
    Our hope is that DALL·E 2 will empower people to express themselves creatively. DALL·E 2 also helps us understand how advanced AI systems see and understand our world, which is critical to our mission of creating AI that benefits humanity.
</p>

<video src="video.mp4" controls mute loop  ></video>

<hr>
<h1 style="color: white;">
    Credits
Research Advancements

Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, Mark Chen



Engineering, Design, Product, and Prototyping

Jeff Belgum, Dave Cummings, Jonathan Gordon, Chris Hallacy, Shawn Jain, Joanne Jang, Fraser Kelton, Vishal Kuo, Joel Lehman, Rachel Lim, Bianca Martin, Evan Morikawa, Rajeev Nayak, Glenn Powell, Krijn Rijshouwer, David Schnurr, Maddie Simens, Kenneth Stanley, Felipe Such, Chelsea Voss, Justin Jay Wang



Comms, Policy, Legal, Ops, Safety, and Security

Steven Adler, Lama Ahmad, Miles Brundage, Kevin Button, Che Chang, Fotis Chantzis, Derek Chen, Frances Choi, Steve Dowling, Elie Georges, Shino Jomoto, Aris Konstantinidis, Gretchen Krueger, Andrew Mayne, Pamela Mishkin, Bob Rotsted, Natalie Summers, Dave Willner, Hannah Wong



Acknowledgments

Thanks to those who helped with and provided feedback on this release: Sandhini Agarwal, Sam Altman, Chester Cho, Peter Hoeschele, Jacob Jackson, Jong Wook Kim, Matt Knight, Jason Kwon, Anna Makanju, Katie Mayer, Bob McGrew, Luke Miller, Mira Murati, Adam Nace, Hyeonwoo Noh, Cullen O’Keefe, Long Ouyang, Michael Petrov, Henrique Ponde de Oliveira Pinto, Alec Radford, Girish Sastry, Pranav Shyam, Aravind Srinivas, Ilya Sutskever, Preston Tuggle, Arun Vijayvergiya, Peter Welinder
</h1>
<hr>
<h1 style="color: white; font-size: 89px;">Start creating images with DALL·E.</h1>

<div class="divb">
   <center>
    <a class="linky" href="https://auth0.openai.com/u/signup/identifier?state=hKFo2SBUZEZUQm5fZ3hyOFlES3NJZDY0MW81bEtvbHBFeV9LeaFur3VuaXZlcnNhbC1sb2dpbqN0aWTZIHMyYUlpSDRNaXBpeUZpVVhnbEFLSS1oSDJPLUlkZ2tIo2NpZNkgRE1nOTFmNVBDSFF0Yzd1MDE4V0tpTDB6b3BLZGlIbGU">Try DALL.E&#8227;</a>
   </center>
   </div>

   <ul class="display" >
    <li>Twitter</li>
<li >Youtube</li>
<li>Github</li>
<li>Soundcloud</li>
<li>linkedln</li>


</ul>

<h1 style="color: white; text-align: justify; ">
OpenAI © 2015 – 2023 <br>
Terms & policies <br>
Privacy policy <br>
Brand guidelines <br>
</h1>
<h1 style="color: white;  margin-left: 498px;  ">back to top &#8593;</h1>

<img width="1800px" src="Capture.JPG" alt="">





</body>
</html>